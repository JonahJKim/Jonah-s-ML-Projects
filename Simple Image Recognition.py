# -*- coding: utf-8 -*-
"""ImageSynthesis

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NVAOX1syiYOyHtSDQA3CXjLRYGiNYQM0
"""

import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

batch_size = 4

transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

trainset = torchvision.datasets.CIFAR10('./data', train=True, download=True, transform=transform)
trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10('./data', train=False, download=True, transform=transform)
testloader = DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers = 2)

classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

import matplotlib.pyplot as plt
import numpy as np
def imageshow(img):
  img = img / 2 + 0.5
  np_img = img.numpy()
  plt.imshow(np.transpose(np_img, (1, 2, 0)))
  plt.show()

import torch.nn as nn
import torch.nn.functional as F

class ConvNet(nn.Module):
  def __init__(self):
    super().__init__()
    self.conv1 = nn.Conv2d(3, 6, 5)
    self.pool = nn.MaxPool2d(2, 2)
    self.conv2 = nn.Conv2d(6, 16, 5)
    self.fc1 = nn.Linear(16 * 5 * 5, 120)
    self.fc2 = nn.Linear(120, 84)
    self.fc3 = nn.Linear(84, 10)
  
  def forward(self, x):
    x = F.relu(self.conv1(x))
    x = self.pool(x)

    x = F.relu(self.conv2(x))
    x = self.pool(x)
    
    x = torch.flatten(x, 1)

    x = self.fc1(x)
    x = self.fc2(x)
    x = self.fc3(x)
    return x
model = ConvNet()

torch.save(model.state_dict(), 'ImageClassificationModel.py')

import torch.optim as optim

lr = 1e-3
epochs = 3
momentum = 0.9

loss_fn = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)

def get_train_step(model, loss_fn, optimizer):
  def train_step(x, y):
    yhat = model(x)
    loss = loss_fn(yhat, y)
    loss.backward()

    optimizer.step()
    optimizer.zero_grad()
    return loss.item()
  return train_step

device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
model.to(device)
train_step = get_train_step(model, loss_fn, optimizer)
for epoch in range(epochs):
  model.train()

  for i, data in enumerate(trainloader):
    xbatch, ybatch = data
    xbatch.to(device)
    ybatch.to(device)
    loss = train_step(xbatch, ybatch)

    if i % 1500 == 0:
      print(f'Iteration {i}: {loss}')

correct = {classitem: 0 for classitem in classes}
total = {classitem: 0 for classitem in classes}

with torch.no_grad():
  for xbatch, ybatch in testloader:
      xbatch.to(device)
      ybatch.to(device)

      prediction = model(xbatch)
      _, prediction = torch.max(prediction, 1)

      for label, prediction in zip(ybatch, prediction):
        total[classes[label]] += 1
        if label == prediction:
          correct[classes[label]] += 1
    
for classname, total_count in total.items():
  print(f'Accuracy for {classname} is {float(correct[classname]) / total_count}%')



# correct = {classitem: 0 for classitem in classes}
# total = {classitem: 0 for classitem in classes}

# with torch.no_grad():
#   for xbatch, ybatch in testloader:
#       xbatch.to(device)
#       ybatch.to(device)

#       prediction = model(xbatch)
#       _, prediction = torch.max(prediction, 1)

#       for i, predict in enumerate(prediction):

#       total += ybatch.size(0)
#       correct += (prediction == ybatch).sum().item()
    
# print(f'Accuracy: {100 * correct // total}%')