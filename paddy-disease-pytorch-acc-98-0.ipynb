{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom os import walk\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import models, transforms\nfrom tqdm import tqdm","metadata":{"_uuid":"6b80ea23-760c-4e21-b759-3d395d6b3796","_cell_guid":"105bd75e-2845-4611-a7df-83736090026e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-04T06:41:46.296121Z","iopub.execute_input":"2022-08-04T06:41:46.296606Z","iopub.status.idle":"2022-08-04T06:41:46.306915Z","shell.execute_reply.started":"2022-08-04T06:41:46.296570Z","shell.execute_reply":"2022-08-04T06:41:46.305893Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# pre-setup\nHP = {'epochs': 25, 'batch_size': 32, 'learning_rate': 1e-3, 'momentum': 0.9, 'test_size': 0.05,'seed': 1}\ntorch.manual_seed(HP['seed'])\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nif device == 'cuda':\n    torch.backends.cudnn.benchmark = True\nprint(f'using {device} device')\n\ndataset_dir = '/kaggle/input/paddy-disease-classification/train_images/'\nsubmission_dir = '/kaggle/input/paddy-disease-classification/test_images/'\ndataset_file = '/kaggle/input/paddy-disease-classification/train.csv'\nsubmission_sample = '/kaggle/input/paddy-disease-classification/sample_submission.csv'\nsubmission_output = '/kaggle/working/submission.csv'\n","metadata":{"_uuid":"068549fa-6ea1-4b67-93f3-87fd1c8e0bc7","_cell_guid":"cd2077fc-a2dc-4ab1-abb7-544541c9afa6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-04T06:55:09.509994Z","iopub.execute_input":"2022-08-04T06:55:09.510875Z","iopub.status.idle":"2022-08-04T06:55:09.520609Z","shell.execute_reply.started":"2022-08-04T06:55:09.510834Z","shell.execute_reply":"2022-08-04T06:55:09.519288Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# data processing block\ndf = pd.read_csv(dataset_file)\n\n# shuffle dataset\ndf = shuffle(df, random_state=HP['seed'])\n\n# replace category column with numbers\ndf['variety'] = pd.factorize(df['variety'])[0] # replaces category with number\n\n# create index -> label and vice versa dictionaries\nidx_to_label = df['label'].unique()\nlabel_to_idx = {idx: label for label, idx in enumerate(idx_to_label)}\n\n# create train/val split\ntrain_df, test_df = train_test_split(df, test_size=HP['test_size'])\nprint(f'train len: {len(train_df)}, test len: {len(test_df)}')","metadata":{"_uuid":"7529e3de-8244-4aa5-b636-8f1790a75a9c","_cell_guid":"acea0027-18f1-47e0-b3ac-0c3ad0860341","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-04T06:55:09.681924Z","iopub.execute_input":"2022-08-04T06:55:09.682611Z","iopub.status.idle":"2022-08-04T06:55:09.708408Z","shell.execute_reply.started":"2022-08-04T06:55:09.682558Z","shell.execute_reply":"2022-08-04T06:55:09.707297Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-04T06:55:09.760817Z","iopub.execute_input":"2022-08-04T06:55:09.761885Z","iopub.status.idle":"2022-08-04T06:55:09.773214Z","shell.execute_reply.started":"2022-08-04T06:55:09.761845Z","shell.execute_reply":"2022-08-04T06:55:09.772072Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# image transforms block\n# for train dataset\ntrain_transform = transforms.Compose([transforms.RandomHorizontalFlip(), \n                                      transforms.RandomVerticalFlip(), \n                                      transforms.RandomChoice([transforms.Pad(padding=10), transforms.CenterCrop(480), transforms.RandomRotation(20),transforms.CenterCrop((576,432)),transforms.ColorJitter(brightness=0.1,contrast=0.1, saturation=0.1,hue=0.1)]),\n                                      transforms.Resize((224,224)),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n\n# for test dataset\ntest_transform = transforms.Compose([transforms.Resize((224,224)),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])","metadata":{"execution":{"iopub.status.busy":"2022-08-04T06:55:14.248876Z","iopub.execute_input":"2022-08-04T06:55:14.250144Z","iopub.status.idle":"2022-08-04T06:55:14.258584Z","shell.execute_reply.started":"2022-08-04T06:55:14.250103Z","shell.execute_reply":"2022-08-04T06:55:14.257482Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"'''\nIMPORTANT:\n\n__getitem__ in custom dataset is the SAME as collate_fn (both have df['path'] initialized and only translate to tensor on needed basis)\nIn general: both are interchangeable.\n- if you have custom dataset, __getitem__ replaces your collate_fn\n- if you have collate_fn, you don't need __getitem__\n\ntorchvision: mainly custom dataset\ntorchtext: mainly collate_fn\n\nTODO: Do both implementations\n'''\n\n\n# custom dataset class (could have used regular dataset if you did preprocessing on the data before loading it in)\n\n# option 1: do all preprocessing on dataframe itself and create a list dataset with zip(), then use default DataLoader (BAD because overflows memory)\n# it is better to change to tensor one example at a time!\n\n# option 2: create custom dataset class that does preprocessing for you \n\nclass PaddyDataset(Dataset):\n    def __init__(self, dataset_dir, df, label_to_idx, transforms):\n        self.df = df\n        self.label_to_idx = label_to_idx\n        self.transforms = transforms\n        self.df['path'] = dataset_dir + '/' + self.df.label + '/' + self.df.image_id\n        # 0: image_id, 1: label, 2: variety, 3: age, 4: path\n        self.df = self.df.values.tolist()\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df[idx]\n        image = Image.open(row[4])\n#         converter = transforms.ToTensor()\n#         print(converter(image))\n        image = self.transforms(image)\n        idx = self.label_to_idx[row[1]]\n        return image, idx\n\n# add tensor image column to dataframe and use standard dataset\n# df['path'] = dataset_dir + '/' + df.label + '/' + df.image_id\n# converter = transforms.ToTensor()\n# train_data = list(zip(df['label'], df['path']))\n\n# def collate_fn(batch):\n#     label_list, image_list = [], []\n#     for label, image in batch:\n#         label_list.append(label_to_idx[label])\n#         image_list.append(train_transform(Image.open(image)))\n#     label_list = torch.tensor(label_list, dtype=torch.int64)\n#     image_list = torch.nn.utils.rnn.pad_sequence(image_list)\n# #     print(type(image_list))\n#     return label_list, image_list\n\n# train_dataloader = DataLoader(train_data, batch_size=8, shuffle=True, collate_fn=collate_fn)\n\n    \n# image = Image.open(dataset_dir + '/' + df.label + '/' + df.image_id)\n# self.df['image'] = transforms.ToTensor(Image.open(dataset_dir + '/' + df.label + '/' + df.image_id))\n\n# creates datasets \ntrain_dataset = PaddyDataset(dataset_dir, train_df, label_to_idx, train_transform)\ntest_dataset = PaddyDataset(dataset_dir, test_df, label_to_idx, test_transform)\n\n# creates dataloaders\ntrain_dataloader = DataLoader(train_dataset, batch_size=HP['batch_size'], shuffle=True, pin_memory=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=HP['batch_size'], shuffle=True, pin_memory=True)","metadata":{"_uuid":"2e430d2f-360d-44f8-b498-e1e51f3f82c9","_cell_guid":"be09c486-e082-4c0f-8022-1e839932e9d0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-04T06:55:24.728497Z","iopub.execute_input":"2022-08-04T06:55:24.729182Z","iopub.status.idle":"2022-08-04T06:55:24.753759Z","shell.execute_reply.started":"2022-08-04T06:55:24.729141Z","shell.execute_reply":"2022-08-04T06:55:24.752644Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"next(iter(train_dataloader))[0].shape","metadata":{"execution":{"iopub.status.busy":"2022-08-04T06:55:48.955610Z","iopub.execute_input":"2022-08-04T06:55:48.956385Z","iopub.status.idle":"2022-08-04T06:55:49.510794Z","shell.execute_reply.started":"2022-08-04T06:55:48.956346Z","shell.execute_reply":"2022-08-04T06:55:49.508937Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# model block\n\n# gets pretrained network\nmodel = models.resnet34(pretrained=True)\n\n# changes outer layer to have output of 10\nmodel.fc = nn.Sequential(\n    nn.Dropout(0.1),\n    nn.Linear(model.fc.in_features, len(label_to_idx))\n)\nmodel = model.to(device)\n\n# optimizer / loss_fn\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=HP['learning_rate'], momentum=HP['momentum'])","metadata":{"_uuid":"da7e71ee-c24d-4a2e-9abe-5a70c2454904","_cell_guid":"6d03ae27-a665-41d3-8952-7b6de626239a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-04T05:53:46.471398Z","iopub.execute_input":"2022-08-04T05:53:46.471863Z","iopub.status.idle":"2022-08-04T05:53:54.435230Z","shell.execute_reply.started":"2022-08-04T05:53:46.471834Z","shell.execute_reply":"2022-08-04T05:53:54.434238Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def train(model, criterion, optimizer, train_dataloader, test_dataloader):\n\n    total_train_loss = 0\n    total_test_loss = 0\n    \n    model.train()\n    with tqdm(train_dataloader, unit='batch', leave=False) as pbar:\n        pbar.set_description(f'training')\n        for images, idxs in pbar:\n            images = images.to(device, non_blocking=True)\n            idxs = idxs.to(device, non_blocking=True)\n            output = model(images)\n\n            loss = criterion(output, idxs)\n            total_train_loss += loss.item()\n\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad(set_to_none=True)\n\n    model.eval()\n    with tqdm(test_dataloader, unit='batch', leave=False) as pbar:\n        pbar.set_description(f'testing')\n        for images, idxs in pbar:\n            images = images.to(device, non_blocking=True)\n            idxs = idxs.to(device, non_blocking=True)\n\n            output = model(images)\n            loss = criterion(output, idxs)\n            total_test_loss += loss.item()\n\n    train_acc = total_train_loss / len(train_dataset)\n    test_acc = total_test_loss / len(test_dataset)\n    print(f'Train loss: {train_acc:.4f} Test loss: {test_acc:.4f} ')","metadata":{"_uuid":"5494d587-d236-423c-b45d-e5b6703c9850","_cell_guid":"00d1ae9b-1098-46ae-aecb-f56ebc8552d9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-08-04T05:54:53.292133Z","iopub.execute_input":"2022-08-04T05:54:53.292779Z","iopub.status.idle":"2022-08-04T05:54:53.302848Z","shell.execute_reply.started":"2022-08-04T05:54:53.292740Z","shell.execute_reply":"2022-08-04T05:54:53.301664Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"%%time\nfor i in range(HP['epochs']):\n    print(f\"Epoch {i+1}/{HP['epochs']}\")\n    train(model, criterion, optimizer, train_dataloader, test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-08-04T05:54:58.224025Z","iopub.execute_input":"2022-08-04T05:54:58.224635Z","iopub.status.idle":"2022-08-04T06:08:13.525776Z","shell.execute_reply.started":"2022-08-04T05:54:58.224598Z","shell.execute_reply":"2022-08-04T06:08:13.524709Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"%%time\nmodel.eval()\nimage_ids, labels = [], []\nfor (dirpath, dirname, filenames) in walk(submission_dir):\n    for filename in filenames:\n        image = Image.open(dirpath+filename)\n        image = test_transform(image)\n        image = image.unsqueeze(0).to(device)\n        image_ids.append(filename)\n        labels.append(idx_to_label[model(image).argmax().item()])","metadata":{"_uuid":"1aad70ca-91e7-4dca-b085-2c9323309453","_cell_guid":"a9399787-1f8f-47fc-82ee-dd6076bc55f5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-07-02T17:43:30.398912Z","iopub.execute_input":"2022-07-02T17:43:30.399794Z","iopub.status.idle":"2022-07-02T17:44:41.935602Z","shell.execute_reply.started":"2022-07-02T17:43:30.399753Z","shell.execute_reply":"2022-07-02T17:44:41.934432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'image_id': image_ids,\n    'label': labels,\n})\n# submission['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-02T17:44:41.936943Z","iopub.execute_input":"2022-07-02T17:44:41.937701Z","iopub.status.idle":"2022-07-02T17:44:41.944743Z","shell.execute_reply.started":"2022-07-02T17:44:41.93766Z","shell.execute_reply":"2022-07-02T17:44:41.943453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(submission_output, index=False, header=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-02T17:44:41.947252Z","iopub.execute_input":"2022-07-02T17:44:41.947634Z","iopub.status.idle":"2022-07-02T17:44:41.964703Z","shell.execute_reply.started":"2022-07-02T17:44:41.947596Z","shell.execute_reply":"2022-07-02T17:44:41.963859Z"},"trusted":true},"execution_count":null,"outputs":[]}]}