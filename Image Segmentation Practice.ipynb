{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Image Segmentation Tutorial.ipynb","provenance":[],"authorship_tag":"ABX9TyPofZWE5cIsCnjR2Zy8M94g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":22,"metadata":{"id":"EJ0c40IhRhBS","executionInfo":{"status":"ok","timestamp":1660181348064,"user_tz":420,"elapsed":135,"user":{"displayName":"Jonah Kim","userId":"00689801849154586458"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn \n","import torchvision.transforms.functional as TF\n","import os\n","from PIL import Image\n","from torch.utils.data import Dataset\n","import numpy as np\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from tqdm import tqdm  "]},{"cell_type":"code","source":["# data processing block\n","class CarvanaDataset(Dataset):\n","  def __init__(self, image_dir, mask_dir, transform=None):\n","    super().__init__()\n","    self.image_dir = image_dir\n","    self.mask_dir = mask_dir\n","    self.transform = transform\n","    self.images = os.listdir(image_dir)\n","  \n","  def __len__(self):\n","    return len(self.images)\n","\n","  def __getitem__(self, index):\n","    img_path = os.path.join(self.image_dir, self.images[index])\n","    mask_path = os.path.join(self.mask_dir, self.images[index].replace('.jpg', '_mask.gif'))\n","    image = np.array(Image.open(img_path).convert('RGB'))\n","    mask = np.array(Image.open(mask_path).convert('L'), dtype=np.float32)\n","    \n","    mask[mask==255] = 1.0\n","\n","    if self.transform is not None:\n","      augmentations = self.transform(image=image, mask=mask)\n","      image = augmentations['image']\n","      mask = augmentations['mask']\n","    return image, mask "],"metadata":{"id":"HUfUp_I_c4T3","executionInfo":{"status":"ok","timestamp":1660181348251,"user_tz":420,"elapsed":4,"user":{"displayName":"Jonah Kim","userId":"00689801849154586458"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# one conv step block\n","class DoubleConv(nn.Module):\n","  def __init__(self, in_channels, out_channels):\n","    super().__init__()\n","    # 3x3 kernel, 1 stride, same padding\n","    self.conv = nn.Sequential(nn.Conv2d(in_channels, out_channels, 3, 1, 'same', bias=False),\n","                              nn.BatchNorm2d(out_channels),\n","                              nn.ReLU(inplace=True),\n","                              nn.Conv2d(out_channels, out_channels, 3, 1, 'same', bias=False),\n","                              nn.BatchNorm2d(out_channels),\n","                              nn.ReLU(inplace=True))\n","  def forward(self, x):\n","    return self.conv(x)"],"metadata":{"id":"QqG8iVLxT1HJ","executionInfo":{"status":"ok","timestamp":1660181348251,"user_tz":420,"elapsed":3,"user":{"displayName":"Jonah Kim","userId":"00689801849154586458"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# u-net block\n","class UNet(nn.Module):\n","  def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n","    super().__init__()\n","    self.downs = nn.ModuleList()\n","    self.ups = nn.ModuleList()\n","    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","    # down part\n","    for feature in features:\n","      self.downs.append(DoubleConv(in_channels, feature))\n","      in_channels = feature\n","    \n","    # up part\n","    for feature in reversed(features):\n","      # doubles height and width\n","      self.ups.append(nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2))\n","      self.ups.append(DoubleConv(feature * 2, feature))\n","    \n","    self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n","    self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n","\n","  def forward(self, x):\n","    skip_connections = []\n","\n","    # condense\n","    for down in self.downs:\n","      x = down(x)\n","      skip_connections.append(x)\n","      x = self.pool(x)\n","\n","    # bottleneck\n","    x = self.bottleneck(x)\n","\n","    # expander\n","    skip_connections = skip_connections[::-1]\n","    for idx in range(0, len(self.ups), 2):\n","      x = self.ups[idx](x)\n","      skip_connection = skip_connections[idx // 2]\n","\n","      if x.shape != skip_connection.shape:\n","        x = TF.resize(x, size=skip_connection.shape[2:])\n","\n","      concat_skip = torch.cat((skip_connection, x), dim=1)\n","      x = self.ups[idx + 1](concat_skip)\n","\n","    x = self.final_conv(x)\n","    return x"],"metadata":{"id":"6SAij4a8VgP9","executionInfo":{"status":"ok","timestamp":1660181348251,"user_tz":420,"elapsed":3,"user":{"displayName":"Jonah Kim","userId":"00689801849154586458"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# training set-up block\n","LEARNING_RATE = 1e-4\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","BATCH_SIZE = 16\n","NUM_EPOCHS = 3\n","NUM_WORKERS = 2\n","IMAGE_HEIGHT = 160  # 1280 originally\n","IMAGE_WIDTH = 240  # 1918 originally\n","# PIN_MEMORY = True\n","# LOAD_MODEL = False\n","TRAIN_IMG_DIR = \"data/train_images/\"\n","TRAIN_MASK_DIR = \"data/train_masks/\"\n","VAL_IMG_DIR = \"data/val_images/\"\n","VAL_MASK_DIR = \"data/val_masks/\""],"metadata":{"id":"OXRVxQMiccfX","executionInfo":{"status":"ok","timestamp":1660181348529,"user_tz":420,"elapsed":280,"user":{"displayName":"Jonah Kim","userId":"00689801849154586458"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["def train_fn(loader, model, optimizer, loss_fn, scaler):\n","    loop = tqdm(loader)\n","\n","    for batch_idx, (data, targets) in enumerate(loop):\n","        data = data.to(device=DEVICE)\n","        targets = targets.float().unsqueeze(1).to(device=DEVICE)\n","\n","        # forward\n","        with torch.cuda.amp.autocast():\n","            predictions = model(data)\n","            loss = loss_fn(predictions, targets)\n","\n","        # backward\n","        optimizer.zero_grad()\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        # update tqdm loop\n","        loop.set_postfix(loss=loss.item())\n","\n","train_transform = A.Compose(\n","    [\n","        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n","        A.Rotate(limit=35, p=1.0),\n","        A.HorizontalFlip(p=0.5),\n","        A.VerticalFlip(p=0.1),\n","        A.Normalize(\n","            mean=[0.0, 0.0, 0.0],\n","            std=[1.0, 1.0, 1.0],\n","            max_pixel_value=255.0,\n","        ),\n","        ToTensorV2(),\n","    ],\n",")\n","\n","val_transforms = A.Compose(\n","    [\n","        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n","        A.Normalize(\n","            mean=[0.0, 0.0, 0.0],\n","            std=[1.0, 1.0, 1.0],\n","            max_pixel_value=255.0,\n","        ),\n","        ToTensorV2(),\n","    ],\n",")\n","\n","model = UNet(in_channels=3, out_channels=1).to(DEVICE)\n","loss_fn = nn.BCEWithLogitsLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","\n","train_loader, val_loader = get_loaders(\n","    TRAIN_IMG_DIR,\n","    TRAIN_MASK_DIR,\n","    VAL_IMG_DIR,\n","    VAL_MASK_DIR,\n","    BATCH_SIZE,\n","    train_transform,\n","    val_transforms,\n","    NUM_WORKERS\n",")\n","scaler = torch.cuda.amp.GradScaler()\n","\n","for epoch in range(NUM_EPOCHS):\n","    train_fn(train_loader, model, optimizer, loss_fn, scaler)\n","\n","    # save model\n","    checkpoint = {\n","        \"state_dict\": model.state_dict(),\n","        \"optimizer\":optimizer.state_dict()}\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"id":"2MPWoo-TgsFP","executionInfo":{"status":"error","timestamp":1660181352589,"user_tz":420,"elapsed":4062,"user":{"displayName":"Jonah Kim","userId":"00689801849154586458"}},"outputId":"5ed8986f-35b8-4cff-993a-2b43a5b86461"},"execution_count":27,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-68402024eadd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m train_loader, val_loader = get_loaders(\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mTRAIN_IMG_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mTRAIN_MASK_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'get_loaders' is not defined"]}]}]}