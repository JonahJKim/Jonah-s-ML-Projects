{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP with attention.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "CAcRpLtTaTdI"
      },
      "outputs": [],
      "source": [
        "# !pip install torchtext==0.10.0\n",
        "# !python -m spacy download de\n",
        "# !python -m spacy download en\n",
        "# !pip install -U torchtext==0.8.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import spacy\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "# import torchtext\n",
        "# from torchtext.legacy.datasets import Multi30k\n",
        "# from torchtext.legacy.data import Field, BucketIterator\n",
        "# import spacy\n",
        "# import random\n",
        "# from torch import tensor\n",
        "\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "8Y2mghO8aU9i"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # data processing block\n",
        "# # tokenizer\n",
        "# spacy_ger = spacy.load('de_core_news_sm')\n",
        "# spacy_eng = spacy.load('en_core_web_sm')\n",
        "\n",
        "# def ger_tokenizer(text): return [tok.text for tok in spacy_ger.tokenizer(text)]\n",
        "# def eng_tokenizer(text): return [tok.text for tok in spacy_eng.tokenizer(text)]\n",
        "\n",
        "# # field\n",
        "# german = Field(tokenize=ger_tokenizer, lower=True, init_token='<sos>', eos_token='<eos>')\n",
        "# english = Field(tokenize=eng_tokenizer, lower=True, init_token='<sos>', eos_token='<eos>')\n",
        "\n",
        "# # dataset\n",
        "# train_data, val_data, test_data = Multi30k.splits(exts=('.de', '.en'), fields=(german, english))\n",
        "\n",
        "# # vocabulary\n",
        "# german.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "# english.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "\n",
        "# # iterator\n",
        "# train_iter, val_iter, test_itr = BucketIterator.splits((train_data, val_data, test_data), batch_size=64, sort_within_batch=True, sort_key=lambda x: len(x.src), device=device)"
      ],
      "metadata": {
        "id": "s_XdvAJQaWlr"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # encoder block\n",
        "# class Encoder(nn.Module):\n",
        "#   def __init__(self, input_size, embedding_size, hidden_size, num_layers, dropout_prob):\n",
        "#     super().__init__()\n",
        "\n",
        "#     self.dropout = nn.Dropout(dropout_prob)\n",
        "#     self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "#     self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout_prob, bidirectional=True)\n",
        "    \n",
        "#     self.fc_hidden = nn.Linear(hidden_size * 2, hidden_size) # combines the forward and backward hidden layers for each word\n",
        "#     self.fc_cell = nn.Linear(hidden_size * 2, hidden_size) # same thing for cell\n",
        "\n",
        "#   def forward(self, x):\n",
        "#     embedding = self.dropout(self.embedding(x))\n",
        "\n",
        "#     # IMPORTANT: encoder_states contains every hidden value for every time step! (all calcuated in one pass through LSTM block because x has all the time steps in 1st dim)\n",
        "#     # hidden, cell contain only the 2 context vectors (1 from forward pass and 1 from backward pass). Use small neural network to combine the two\n",
        "#     # (just like when encoder_states was output, output would contain the output for every individual time step)\n",
        "#     encoder_states, (hidden, cell) = self.rnn(embedding) \n",
        "#     # encoder_states: (seq_length, N, hidden_size). Need to do use fc layer to get to output size.\n",
        "\n",
        "\n",
        "#     # hidden shape: (2, N, hidden_size), so want to concatenate on last axis\n",
        "#     hidden = self.fc_hidden(torch.cat((hidden[0:1], hidden[1:2]), dim=2))\n",
        "#     cell = self.fc_cell(torch.cat((cell[0:1], cell[1:2]), dim=2))\n",
        "\n",
        "#     return encoder_states, hidden, cell\n"
      ],
      "metadata": {
        "id": "7KKtNwtGaXy2"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Y_QnVyDgem07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # decoder block\n",
        "# class Decoder(nn.Module):\n",
        "#   def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, dropout_prob):\n",
        "#     super().__init__()\n",
        "\n",
        "#     self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "#     self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "#     # hidden_size * 2 because encoder_states is same size as hidden_size, and it is bidirectional.\n",
        "#     self.rnn = nn.LSTM(hidden_size * 2 + embedding_size, hidden_size, num_layers, dropout=dropout_prob)\n",
        "\n",
        "#     # 2 hidden_state sizes from encoder_states, 1 hidden_state size from the previous decoder output s(-1)\n",
        "#     self.energy = nn.Linear(hidden_size * 3, 1)\n",
        "\n",
        "#     self.softmax = nn.Softmax(dim=0) # why dim=0?\n",
        "#     self.relu = nn.ReLU()\n",
        "\n",
        "#     self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "#   def forward(self, x, encoder_states, hidden, cell):\n",
        "#     x = x.unsqueeze(0)\n",
        "#     embedded = self.dropout(self.embedding(x))\n",
        "\n",
        "#     sequence_length = encoder_states.shape[0]\n",
        "#     h_reshaped = hidden.repeat(sequence_length, 1, 1)\n",
        "#     energy = self.relu(self.energy(torch.cat((h_reshaped, encoder_states), dim=2))) # h_reshaped: hidden_size * 1, encoder_states: hidden_size * 2\n",
        "#     attention = self.softmax(energy)\n",
        "\n",
        "#     attention = attention.permute(1, 2, 0)\n",
        "#     encoder_states = encoder_states.permute(1, 0, 2)\n",
        "\n",
        "#     context_vector = torch.bmm(attention, encoder_states).permute(1, 0, 2)\n",
        "\n",
        "#     rnn_input = torch.cat((context_vector, embedded), dim=2)\n",
        "\n",
        "#     # attention: (seq_length, N, 1)\n",
        "\n",
        "#     # attention = attention_weight * encoder_states\n",
        "#     # how to calculate attention_weight?\n",
        "    \n",
        "\n",
        "#     output, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
        "#     output = self.fc(output)\n",
        "#     output = output.squeeze(0)\n",
        "#     return output, hidden, cell"
      ],
      "metadata": {
        "id": "a8KmjlALaYwi"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Seq2Seq block\n",
        "# class Seq2Seq(nn.Module):\n",
        "#   def __init__(self, encoder, decoder):\n",
        "#     super().__init__()\n",
        "\n",
        "#     self.encoder = encoder\n",
        "#     self.decoder = decoder\n",
        "\n",
        "#   def forward(self, source, target, teacher_forcing_ratio = 0.5):\n",
        "#     encoder_states, hidden, cell = self.encoder(source)\n",
        "#     outputs = torch.zeros((len(target), len(target[0]), len(english.vocab))).to(device)\n",
        "#     x = target[0]\n",
        "#     for i in range(1, len(target)):\n",
        "#       output, hidden, cell = self.decoder(x, encoder_states, hidden, cell)\n",
        "#       outputs[i] = output\n",
        "#       best_guess = output.argmax(1)\n",
        "#       x = target[i] if random.random() < teacher_forcing_ratio else best_guess\n",
        "#     return outputs"
      ],
      "metadata": {
        "id": "BuDI6H8naZy9"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # train set-up block\n",
        "\n",
        "# encoder_input_size = len(german.vocab)\n",
        "# decoder_input_size = len(english.vocab)\n",
        "# output_size = len(english.vocab)\n",
        "# epochs = 20\n",
        "# lr = 0.001\n",
        "# num_layers = 1\n",
        "# dropout_prob = 0.5\n",
        "# embedding_size = 300\n",
        "# hidden_size = 1024\n",
        "\n",
        "# encoder = Encoder(encoder_input_size, embedding_size, hidden_size, num_layers, dropout_prob).to(device)\n",
        "# decoder = Decoder(decoder_input_size, embedding_size, hidden_size, output_size, num_layers, dropout_prob).to(device)\n",
        "# model = Seq2Seq(encoder, decoder).to(device)\n",
        "\n",
        "# loss_fn = nn.CrossEntropyLoss(ignore_index=english.vocab.stoi['<pad>'])\n",
        "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# sentence = \"ein boot mit mehreren männern darauf wird von einem großen pferdegespann ans ufer gezogen.\""
      ],
      "metadata": {
        "id": "CbEOYaiGaaqI"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # HELPER\n",
        "# def translate_sentence(model, sentence, german, english, device, max_length=50):\n",
        "#     spacy_ger = spacy.load(\"de_core_news_sm\")\n",
        "#     if type(sentence) == str: tokens = [token.text.lower() for token in spacy_ger(sentence)]\n",
        "#     else: tokens = [token.lower() for token in sentence]\n",
        "#     tokens.insert(0, german.init_token)\n",
        "#     tokens.append(german.eos_token)\n",
        "#     text_to_indices = [german.vocab.stoi[token] for token in tokens]\n",
        "#     sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
        "#     with torch.no_grad(): encoder_states, hidden, cell = model.encoder(sentence_tensor)\n",
        "#     outputs = [english.vocab.stoi[\"<sos>\"]]\n",
        "#     for _ in range(max_length):\n",
        "#         previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
        "#         with torch.no_grad():\n",
        "#             output, hidden, cell = model.decoder(previous_word, encoder_states, hidden, cell)\n",
        "#             best_guess = output.argmax(1).item()\n",
        "#         outputs.append(best_guess)\n",
        "#         if output.argmax(1).item() == english.vocab.stoi[\"<eos>\"]: break\n",
        "#     translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
        "#     return translated_sentence[1:]"
      ],
      "metadata": {
        "id": "iBF6PPaDabir"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # training block\n",
        "\n",
        "# for epoch in range(epochs):\n",
        "#   model.eval()\n",
        "#   print(f'Epoch: [{epoch} / {epochs}]')\n",
        "#   training_sentence = translate_sentence(model, sentence, german, english, device)\n",
        "#   print(f'Sentence: \\n {training_sentence}')\n",
        "\n",
        "#   model.train()\n",
        "#   for i, batch in enumerate(train_iter):\n",
        "#     xbatch = batch.src.to(device)\n",
        "#     ybatch = batch.trg.to(device)\n",
        "\n",
        "#     output = model(xbatch, ybatch)\n",
        "\n",
        "#     output = output[1:].reshape(-1, output.shape[2])\n",
        "#     ybatch = ybatch[1:].reshape(-1)\n",
        "\n",
        "#     loss = loss_fn(output, ybatch)\n",
        "#     loss.backward()\n",
        "\n",
        "#     optimizer.step()\n",
        "#     optimizer.zero_grad()\n"
      ],
      "metadata": {
        "id": "tDEendOgadVW"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "from torchtext.legacy.datasets import Multi30k\n",
        "from torchtext.legacy.data import Field, BucketIterator\n",
        "import spacy\n",
        "import random\n",
        "from torch import tensor\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "2B-7Owyuaedi"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data processing block\n",
        "\n",
        "spacy_ger = spacy.load('de_core_news_sm')\n",
        "spacy_eng = spacy.load('en_core_web_sm')\n",
        "\n",
        "# tokenizers for field\n",
        "def ger_tokenizer(text): return [tok.text for tok in spacy_ger.tokenizer(text)]\n",
        "def eng_tokenizer(text): return [tok.text for tok in spacy_eng.tokenizer(text)]\n",
        "\n",
        "# fields\n",
        "german = Field(tokenize=ger_tokenizer, lower=True, init_token='<sos>', eos_token='<eos>')\n",
        "english = Field(tokenize=eng_tokenizer, lower=True, init_token='<sos>', eos_token='<eos>')\n",
        "\n",
        "# datasets\n",
        "train_data, val_data, test_data = Multi30k.splits(exts=('.de', '.en'), fields=(german, english))\n",
        "\n",
        "# vocabulary\n",
        "german.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "english.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "\n",
        "# iterators\n",
        "train_iter, val_itr, test_itr = BucketIterator.splits((train_data, val_data, test_data), batch_size=64, sort_within_batch=True, sort_key=lambda x: len(x.src), device=device)"
      ],
      "metadata": {
        "id": "pYyPwNs4agAg"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unicodedata import bidirectional\n",
        "# encoding block\n",
        "class Encoder(nn.Module):\n",
        "  # input size: german_vocab size, embedding_size: 300, hidden_size: 1024, num_layers: 2, dropout_prob: 0.5\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, dropout_prob):\n",
        "    super().__init__()\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout_prob)\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "    self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout_prob)\n",
        "\n",
        "  def forward(self, x):\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "\n",
        "    output, (hidden, cell) = self.rnn(embedding)\n",
        "\n",
        "    return hidden, cell"
      ],
      "metadata": {
        "id": "EyocUeffnwfo"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder block\n",
        "class Decoder(nn.Module):\n",
        "  # input_size: english_vocab size, embedding_size: 300, hidden_size: 1024, num_layers:2, dropout_prob:0.5\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, dropout_prob):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(dropout_prob)\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "    self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout_prob)\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, x, hidden, cell):\n",
        "    x = x.unsqueeze(0)\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    output, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
        "    output = self.fc(output)\n",
        "    output = output.squeeze(0)\n",
        "    return output, hidden, cell"
      ],
      "metadata": {
        "id": "tA0SbEYzhPBN"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seq2seq block\n",
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "  \n",
        "  def forward(self, source, target, teacher_force_ratio=0.5):\n",
        "    hidden, cell = self.encoder(source)\n",
        "\n",
        "    outputs = torch.zeros(len(target), len(target[0]), len(english.vocab)).to(device)\n",
        "    # <sos> token\n",
        "    x = target[0]\n",
        "    for i in range(1, len(target)):\n",
        "      output, hidden, cell = self.decoder(x, hidden, cell)\n",
        "      outputs[i] = output\n",
        "      best_guess = output.argmax(1)\n",
        "      x = target[i] if random.random() < teacher_force_ratio else best_guess\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "ji4dKeMOhPPp"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training set-up block\n",
        "encoder_input_size = len(german.vocab)\n",
        "decoder_input_size = len(english.vocab)\n",
        "output_size = len(english.vocab)\n",
        "\n",
        "embedding_size = 300\n",
        "hidden_size = 1024\n",
        "num_layers = 2\n",
        "epochs = 20\n",
        "lr = 0.001\n",
        "dropout_prob = 0.5\n",
        "\n",
        "encoder = Encoder(encoder_input_size, embedding_size, hidden_size, num_layers, dropout_prob).to(device)\n",
        "decoder = Decoder(decoder_input_size, embedding_size, hidden_size, output_size, num_layers, dropout_prob).to(device)\n",
        "model = Seq2Seq(encoder, decoder).to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=english.vocab.stoi['<pad>'])\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "sentence = \"ein boot mit mehreren männern darauf wird von einem großen pferdegespann ans ufer gezogen.\""
      ],
      "metadata": {
        "id": "P0WqALaznyex"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HELPER\n",
        "def translate_sentence(model, sentence, german, english, device, max_length=50):\n",
        "    spacy_ger = spacy.load(\"de_core_news_sm\")\n",
        "    if type(sentence) == str: tokens = [token.text.lower() for token in spacy_ger(sentence)]\n",
        "    else: tokens = [token.lower() for token in sentence]\n",
        "    tokens.insert(0, german.init_token)\n",
        "    tokens.append(german.eos_token)\n",
        "    text_to_indices = [german.vocab.stoi[token] for token in tokens]\n",
        "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
        "    with torch.no_grad(): hidden, cell = model.encoder(sentence_tensor)\n",
        "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
        "    for _ in range(max_length):\n",
        "        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.decoder(previous_word, hidden, cell)\n",
        "            best_guess = output.argmax(1).item()\n",
        "        outputs.append(best_guess)\n",
        "        if output.argmax(1).item() == english.vocab.stoi[\"<eos>\"]: break\n",
        "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
        "    return translated_sentence[1:]"
      ],
      "metadata": {
        "id": "mvVbe_rFqds2"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training block\n",
        "for epoch in range(epochs):\n",
        "  print(f'Epoch: [{epoch} / {epochs}]')\n",
        "  training_sentence = translate_sentence(model, sentence, german, english, device)\n",
        "  print(f'Sentence: \\n {training_sentence}')\n",
        "\n",
        "  for i, batch in enumerate(train_iter):\n",
        "    xbatch = batch.src.to(device)\n",
        "    ybatch = batch.trg.to(device)\n",
        "    outputs = model(xbatch, ybatch)\n",
        "\n",
        "    outputs = outputs[1:].reshape(-1, outputs.shape[2])\n",
        "    ybatch = ybatch[1:].reshape(-1)\n",
        "\n",
        "    loss = loss_fn(outputs, ybatch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "hCJReKHtoXSX",
        "outputId": "42ecaae8-b251-4082-b942-78aa82ca1271"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [20 / 20]\n",
            "Sentence: \n",
            " ['latin', 'lemons', 'lemons', 'cheeks', 'inspired', 'fallen', 'pan', 'newly', 'legs', 'hides', 'pause', 'sandals', 'drive', 'drive', 'bookshelf', 'torch', 'rig', 'rig', 'rig', 'rates', 'rates', 'rates', 'breaks', 'breaks', 'arguing', 'khakis', 'environment', 'packages', 'applies', 'gazing', 'oxen', 'carve', 'tickets', 'motorbikes', 'torch', 'torch', 'home', 'facing', 'braids', 'grasping', 'coolers', 'hides', 'arrival', 'arrival', 'so', 'dolls', 'trinkets', 'fighter', 'slam', 'baked']\n",
            "Epoch: [20 / 20]\n",
            "Sentence: \n",
            " ['a', 'black', 'and', 'a', 'dog', 'in', 'a', 'red', 'shirt', 'and', 'a', 'a', 'a', '.', '<eos>']\n",
            "Epoch: [20 / 20]\n",
            "Sentence: \n",
            " ['a', 'snowboarder', 'with', 'a', 'is', 'is', 'a', 'a', 'a', 'a', 'a', 'a', 'a', '.', '<eos>']\n",
            "Epoch: [20 / 20]\n",
            "Sentence: \n",
            " ['a', 'worker', 'with', 'a', '<unk>', 'is', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', '.', '<eos>']\n",
            "Epoch: [20 / 20]\n",
            "Sentence: \n",
            " ['a', 'race', 'with', 'with', 'a', '<unk>', 'is', 'being', 'pulled', 'on', 'a', 'a', 'a', 'a', '.', '<eos>']\n",
            "Epoch: [20 / 20]\n",
            "Sentence: \n",
            " ['a', 'boat', 'with', 'a', '<unk>', 'is', 'being', 'pulled', 'by', 'a', 'large', 'large', 'large', '.', '.', '<eos>']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-71748ab1c0f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Sentence: \\n {training_sentence}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mxbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mybatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                         \u001b[0mminibatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/data/batch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, dataset, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/data/field.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, batch, device)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \"\"\"\n\u001b[1;32m    230\u001b[0m         \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/legacy/data/field.py\u001b[0m in \u001b[0;36mnumericalize\u001b[0;34m(self, arr, device)\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "y_nD86gnqrYS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}